{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_clip = VideoFileClip(\"train_sample_videos/aagfhgtpmv.mp4\")\n",
    "# audio = video_clip.audio\n",
    "\n",
    "# # Step 2: Convert the audio into an array of samples\n",
    "# fps = audio.fps  # frames per second (sampling rate)\n",
    "# audio_samples = np.array(list(audio.iter_frames(fps=fps, dtype=\"float32\"))).flatten()\n",
    "\n",
    "# # Step 3: Use an in-memory buffer to store the audio as a .wav file\n",
    "# buffer = io.BytesIO()\n",
    "# sf.write(buffer, audio_samples, fps, format='wav')  # Store audio in buffer as .wav\n",
    "# buffer.seek(0)  # Reset buffer to the beginning\n",
    "\n",
    "# # Step 4: Load audio from buffer using librosa\n",
    "# x, sr = librosa.load(buffer, sr=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Features  \n",
    "A first easy step is to compute the mean, standard deviation, minimum, maximum, median and quartiles of the frequencies of each signal. This can be done using Numpy and it always brings value to our feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqs = np.fft.fftfreq(x.size)\n",
    "\n",
    "# def describe_freq(freqs):\n",
    "#     mean = np.mean(freqs)\n",
    "#     std = np.std(freqs)\n",
    "#     maxv = np.amax(freqs)\n",
    "#     minv = np.amin(freqs)\n",
    "#     median = np.median(freqs)\n",
    "#     skew = scipy.stats.skew(freqs)\n",
    "#     kurt = scipy.stats.kurtosis(freqs)\n",
    "#     q1 = np.quantile(freqs, 0.25)\n",
    "#     q3 = np.quantile(freqs, 0.75)\n",
    "#     mode = scipy.stats.mode(freqs)[0][0]\n",
    "#     iqr = scipy.stats.iqr(freqs)\n",
    "\n",
    "#     return [mean, std, maxv, minv, median, skew, kurt, q1, q3, mode, iqr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc = list(np.mean(librosa.feature.mfcc(y=x, sr=sr), axis=1))\n",
    "# print(len(mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(x, sr):\n",
    "    rmse = np.mean(librosa.feature.rms(y=x)[0])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(x)[0])\n",
    "    tempo = librosa.beat.tempo(y=x, sr=sr)[0]\n",
    "    mfcc = list(np.mean(librosa.feature.mfcc(y=x, sr=sr), axis=1))\n",
    "    spec_cen = np.mean(librosa.feature.spectral_centroid(y=x, sr=sr))\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=x, sr=sr))\n",
    "    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=x, sr=sr))\n",
    "    spectral_flatness = np.mean(librosa.feature.spectral_flatness(y=x))\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=x, sr=sr))\n",
    "    features = [rmse, zcr, tempo, spec_cen, spectral_bandwidth, spectral_contrast, spectral_flatness, spectral_rolloff]\n",
    "    return features + mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_names = ['FileName', 'rmse', 'zcr', 'tempo', 'spectral_centroid', 'spectral_bandwidth', 'spectral_contrast', 'spectral_flatness', 'spectral_rolloff'] + ['mfcc' + str(i) for i in range(1, 21)] + ['label']\n",
    "# file_names = glob.glob(\"train_sample_videos/*.mp4\")\n",
    "# df = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = \"train_sample_videos/aagfhgtpmv.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_audio_dir = r\"REAL\"\n",
    "fake_audio_dir = r\"FAKE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    try:\n",
    "        # Load the video file\n",
    "        video_clip = VideoFileClip(file_path)\n",
    "        audio = video_clip.audio\n",
    "        fps = audio.fps\n",
    "        audio_samples = np.array(\n",
    "            list(audio.iter_frames(fps=fps, dtype=\"float32\"))\n",
    "        ).flatten()\n",
    "        buffer = io.BytesIO()\n",
    "        sf.write(buffer, audio_samples, fps, format=\"wav\")\n",
    "        buffer.seek(0)\n",
    "        x, sr = librosa.load(buffer, sr=None)\n",
    "        features = get_features(x, sr)\n",
    "\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_path}, {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_data(real_dir, fake_dir):\n",
    "    \"\"\"Load and process audio files from real and fake directories.\"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Process real audio files\n",
    "    for file_name in os.listdir(real_dir):\n",
    "        file_path = os.path.join(real_dir, file_name)\n",
    "        features = extract_features(file_path)\n",
    "        if features is not None:\n",
    "            features[\"label\"] = 0  # 0 for REAL\n",
    "            data.append(features)\n",
    "\n",
    "    # Process fake audio files\n",
    "    for file_name in os.listdir(fake_dir):\n",
    "        file_path = os.path.join(fake_dir, file_name)\n",
    "        features = extract_features(file_path)\n",
    "        if features is not None:\n",
    "            features[\"label\"] = 1  # 1 for FAKE\n",
    "            data.append(features)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    columns = (\n",
    "        [\n",
    "            \"rmse\",\n",
    "            \"zcr\",\n",
    "            \"tempo\",\n",
    "            \"spectral_centroid\",\n",
    "            \"spectral_bandwidth\",\n",
    "            \"spectral_contrast\",\n",
    "            \"spectral_flatness\",\n",
    "            \"spectral_rolloff\",\n",
    "        ]\n",
    "        + [f\"mfcc{i}\" for i in range(1, 21)]\n",
    "        + [\"label\"]\n",
    "    )\n",
    "\n",
    "    return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"rmse\",\n",
    "        \"zcr\",\n",
    "        \"tempo\",\n",
    "        \"spectral_centroid\",\n",
    "        \"spectral_bandwidth\",\n",
    "        \"spectral_contrast\",\n",
    "        \"spectral_flatness\",\n",
    "        \"spectral_rolloff\",\n",
    "        \"mfcc1\",\n",
    "        \"mfcc2\",\n",
    "        \"mfcc3\",\n",
    "        \"mfcc4\",\n",
    "        \"mfcc5\",\n",
    "        \"mfcc6\",\n",
    "        \"mfcc7\",\n",
    "        \"mfcc8\",\n",
    "        \"mfcc9\",\n",
    "        \"mfcc10\",\n",
    "        \"mfcc11\",\n",
    "        \"mfcc12\",\n",
    "        \"mfcc13\",\n",
    "        \"mfcc14\",\n",
    "        \"mfcc15\",\n",
    "        \"mfcc16\",\n",
    "        \"mfcc17\",\n",
    "        \"mfcc18\",\n",
    "        \"mfcc19\",\n",
    "        \"mfcc20\",\n",
    "        \"label\",]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m load_data(real_audio_dir, fake_audio_dir)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "df = load_data(real_audio_dir, fake_audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in file_names:\n",
    "#     clean_file = file.split(\"/\")[-1]\n",
    "#     video_clip = VideoFileClip(file)\n",
    "#     audio = video_clip.audio\n",
    "#     fps = audio.fps\n",
    "#     audio_samples = np.array(list(audio.iter_frames(fps=fps, dtype=\"float32\"))).flatten()\n",
    "#     buffer = io.BytesIO()\n",
    "#     sf.write(buffer, audio_samples, fps, format='wav')\n",
    "#     buffer.seek(0)\n",
    "#     x, sr = librosa.load(buffer, sr=None)\n",
    "#     label = json.load(open(\"train_sample_videos/metadata.json\"))[clean_file]['label']\n",
    "#     new_row = pd.DataFrame([[clean_file] + get_features(x, sr) + [label]], columns=column_names)\n",
    "#     df = pd.concat([df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"full_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
