{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3eVgsMsJVRY",
    "outputId": "daa7d2ac-02a4-4258-897f-2b1dbdfa7a28"
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import io\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3A9iF-QXJVRZ"
   },
   "source": [
    "Statistical Features  \n",
    "A first easy step is to compute the mean, standard deviation, minimum, maximum, median and quartiles of the frequencies of each signal. This can be done using Numpy and it always brings value to our feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ibnbShbMJVRa"
   },
   "outputs": [],
   "source": [
    "# freqs = np.fft.fftfreq(x.size)\n",
    "\n",
    "# def describe_freq(freqs):\n",
    "#     mean = np.mean(freqs)\n",
    "#     std = np.std(freqs)\n",
    "#     maxv = np.amax(freqs)\n",
    "#     minv = np.amin(freqs)\n",
    "#     median = np.median(freqs)\n",
    "#     skew = scipy.stats.skew(freqs)\n",
    "#     kurt = scipy.stats.kurtosis(freqs)\n",
    "#     q1 = np.quantile(freqs, 0.25)\n",
    "#     q3 = np.quantile(freqs, 0.75)\n",
    "#     mode = scipy.stats.mode(freqs)[0][0]\n",
    "#     iqr = scipy.stats.iqr(freqs)\n",
    "\n",
    "#     return [mean, std, maxv, minv, median, skew, kurt, q1, q3, mode, iqr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nNifSVyDJVRa"
   },
   "outputs": [],
   "source": [
    "# def get_features(x, sr):\n",
    "#     rmse = np.mean(librosa.feature.rms(y=x)[0])\n",
    "#     zcr = np.mean(librosa.feature.zero_crossing_rate(x)[0])\n",
    "#     tempo = librosa.beat.tempo(y=x, sr=sr)[0]\n",
    "#     mfcc = list(np.mean(librosa.feature.mfcc(y=x, sr=sr), axis=1))\n",
    "#     spec_cen = np.mean(librosa.feature.spectral_centroid(y=x, sr=sr))\n",
    "#     spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=x, sr=sr))\n",
    "#     spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=x, sr=sr))\n",
    "#     spectral_flatness = np.mean(librosa.feature.spectral_flatness(y=x))\n",
    "#     spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=x, sr=sr))\n",
    "#     features = [rmse, zcr, tempo, spec_cen, spectral_bandwidth, spectral_contrast, spectral_flatness, spectral_rolloff]\n",
    "#     return features + mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nL9J7Vp9JVRa"
   },
   "outputs": [],
   "source": [
    "fake_audio_dir = (\n",
    "    r\"H:\\.shortcut-targets-by-id\\1jH_pc6mMj0Iu8wLS1r0vggMWpVElJvOU\\SIH2024_DATASET\\FAKE\"\n",
    ")\n",
    "real_audio_dir = (\n",
    "    r\"H:\\.shortcut-targets-by-id\\1jH_pc6mMj0Iu8wLS1r0vggMWpVElJvOU\\SIH2024_DATASET\\REAL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_files = os.listdir(real_audio_dir)\n",
    "fake_files = os.listdir(fake_audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    r\"H:\\.shortcut-targets-by-id\\1jH_pc6mMj0Iu8wLS1r0vggMWpVElJvOU\\SIH2024_DATASET\\real_files.pkl\",\n",
    "    \"wb\",\n",
    ") as f:\n",
    "    pk.dump(real_files, f)\n",
    "\n",
    "with open(\n",
    "    r\"H:\\.shortcut-targets-by-id\\1jH_pc6mMj0Iu8wLS1r0vggMWpVElJvOU\\SIH2024_DATASET\\fake_files.pkl\",\n",
    "    \"wb\",\n",
    ") as f:\n",
    "    pk.dump(fake_files, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    r\"H:\\.shortcut-targets-by-id\\1jH_pc6mMj0Iu8wLS1r0vggMWpVElJvOU\\SIH2024_DATASET\\real_files.pkl\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    real_files = pk.load(f)\n",
    "\n",
    "with open(\n",
    "    r\"H:\\.shortcut-targets-by-id\\1jH_pc6mMj0Iu8wLS1r0vggMWpVElJvOU\\SIH2024_DATASET\\fake_files.pkl\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    fake_files = pk.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = len(real_files) + len(fake_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BUS-nOHOJVRb"
   },
   "outputs": [],
   "source": [
    "def get_features(x, sr):\n",
    "    \"\"\"Extract audio features from the audio signal.\"\"\"\n",
    "    rmse = np.mean(librosa.feature.rms(y=x)[0])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(x)[0])\n",
    "    tempo = librosa.beat.tempo(y=x, sr=sr)[0]\n",
    "    mfcc = list(np.mean(librosa.feature.mfcc(y=x, sr=sr), axis=1))\n",
    "    spec_cen = np.mean(librosa.feature.spectral_centroid(y=x, sr=sr))\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=x, sr=sr))\n",
    "    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=x, sr=sr))\n",
    "    spectral_flatness = np.mean(librosa.feature.spectral_flatness(y=x))\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=x, sr=sr))\n",
    "    features = [\n",
    "        rmse,\n",
    "        zcr,\n",
    "        tempo,\n",
    "        spec_cen,\n",
    "        spectral_bandwidth,\n",
    "        spectral_contrast,\n",
    "        spectral_flatness,\n",
    "        spectral_rolloff,\n",
    "    ]\n",
    "    return features + mfcc\n",
    "\n",
    "\n",
    "def extract_features(file_path):\n",
    "    \"\"\"Extract features from a video file.\"\"\"\n",
    "    try:\n",
    "        # Load the video file\n",
    "        video_clip = VideoFileClip(file_path)\n",
    "        audio = video_clip.audio\n",
    "        fps = audio.fps\n",
    "        audio_samples = np.array(\n",
    "            list(audio.iter_frames(fps=fps, dtype=\"float32\"))\n",
    "        ).flatten()\n",
    "        buffer = io.BytesIO()\n",
    "        sf.write(buffer, audio_samples, fps, format=\"wav\")\n",
    "        buffer.seek(0)\n",
    "        x, sr = librosa.load(buffer, sr=None)\n",
    "        video_clip.close()  # Close the video file\n",
    "        features = get_features(x, sr)\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_path}, {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_data(real_dir, fake_dir, real_files, fake_files):\n",
    "    \"\"\"Load and process audio files from real and fake directories.\"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Define column names\n",
    "    columns = (\n",
    "        [\n",
    "            \"rmse\",\n",
    "            \"zcr\",\n",
    "            \"tempo\",\n",
    "            \"spectral_centroid\",\n",
    "            \"spectral_bandwidth\",\n",
    "            \"spectral_contrast\",\n",
    "            \"spectral_flatness\",\n",
    "            \"spectral_rolloff\",\n",
    "        ]\n",
    "        + [f\"mfcc{i}\" for i in range(1, 21)]\n",
    "        + [\"label\"]\n",
    "    )\n",
    "\n",
    "    # Get total number of files for progress bar\n",
    "    total_files = len(real_files) + len(fake_files)\n",
    "\n",
    "    # Create progress bar\n",
    "    pbar = tqdm(total=total_files, desc=\"Processing files\", unit=\"file\")\n",
    "\n",
    "    # Process real audio files\n",
    "    for file_name in real_files:\n",
    "        file_path = os.path.join(real_dir, file_name)\n",
    "        features = extract_features(file_path)\n",
    "        if features is not None:\n",
    "            features.append(0)  # 0 for REAL\n",
    "            data.append(features)\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({\"Current file\": file_name[:20]})\n",
    "\n",
    "    # Process fake audio files\n",
    "    for file_name in fake_files:\n",
    "        file_path = os.path.join(fake_dir, file_name)\n",
    "        features = extract_features(file_path)\n",
    "        if features is not None:\n",
    "            features.append(1)  # 1 for FAKE\n",
    "            data.append(features)\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({\"Current file\": file_name[:20]})\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # Create DataFrame with the collected data\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1cxXpFqCJVRb"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"rmse\",\n",
    "        \"zcr\",\n",
    "        \"tempo\",\n",
    "        \"spectral_centroid\",\n",
    "        \"spectral_bandwidth\",\n",
    "        \"spectral_contrast\",\n",
    "        \"spectral_flatness\",\n",
    "        \"spectral_rolloff\",\n",
    "        \"mfcc1\",\n",
    "        \"mfcc2\",\n",
    "        \"mfcc3\",\n",
    "        \"mfcc4\",\n",
    "        \"mfcc5\",\n",
    "        \"mfcc6\",\n",
    "        \"mfcc7\",\n",
    "        \"mfcc8\",\n",
    "        \"mfcc9\",\n",
    "        \"mfcc10\",\n",
    "        \"mfcc11\",\n",
    "        \"mfcc12\",\n",
    "        \"mfcc13\",\n",
    "        \"mfcc14\",\n",
    "        \"mfcc15\",\n",
    "        \"mfcc16\",\n",
    "        \"mfcc17\",\n",
    "        \"mfcc18\",\n",
    "        \"mfcc19\",\n",
    "        \"mfcc20\",\n",
    "        \"label\",]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fSpp-6btJVRb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 15/119148 [01:07<176:25:02,  5.33s/file, Current file=ehgdzhkdvo.mp4]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_audio_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_audio_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 77\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(real_dir, fake_dir, real_files, fake_files)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m real_files:\n\u001b[0;32m     76\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(real_dir, file_name)\n\u001b[1;32m---> 77\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 0 for REAL\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 29\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extract features from a video file.\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# Load the video file\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     video_clip \u001b[38;5;241m=\u001b[39m \u001b[43mVideoFileClip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     audio \u001b[38;5;241m=\u001b[39m video_clip\u001b[38;5;241m.\u001b[39maudio\n\u001b[0;32m     31\u001b[0m     fps \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mfps\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py:88\u001b[0m, in \u001b[0;36mVideoFileClip.__init__\u001b[1;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Make a reader\u001b[39;00m\n\u001b[0;32m     87\u001b[0m pix_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgba\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_mask \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb24\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader \u001b[38;5;241m=\u001b[39m \u001b[43mFFMPEG_VideoReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpix_fmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpix_fmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtarget_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mresize_algo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresize_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfps_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Make some of the reader's attributes accessible from the clip\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mduration\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:35\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.__init__\u001b[1;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m infos \u001b[38;5;241m=\u001b[39m \u001b[43mffmpeg_parse_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_duration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mfps_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps \u001b[38;5;241m=\u001b[39m infos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_fps\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m infos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:258\u001b[0m, in \u001b[0;36mffmpeg_parse_infos\u001b[1;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[0;32m    255\u001b[0m     popen_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreationflags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x08000000\u001b[39m\n\u001b[0;32m    257\u001b[0m proc \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mPopen(cmd, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_params)\n\u001b[1;32m--> 258\u001b[0m (output, error) \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m infos \u001b[38;5;241m=\u001b[39m error\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m proc\n",
      "File \u001b[1;32md:\\Python\\Lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\Lib\\subprocess.py:1626\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1626\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1628\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32md:\\Python\\Lib\\threading.py:1147\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32md:\\Python\\Lib\\threading.py:1167\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1168\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = load_data(real_audio_dir, fake_audio_dir, real_files, fake_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tLFhSuVJVRc"
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMej7SKRJVRc"
   },
   "outputs": [],
   "source": [
    "# for file in file_names:\n",
    "\n",
    "#     clean_file = file.split(\"/\")[-1]\n",
    "#     video_clip = VideoFileClip(file)\n",
    "#     audio = video_clip.audio\n",
    "#     fps = audio.fps\n",
    "#     audio_samples = np.array(list(audio.iter_frames(fps=fps, dtype=\"float32\"))).flatten()\n",
    "#     buffer = io.BytesIO()\n",
    "#     sf.write(buffer, audio_samples, fps, format='wav')\n",
    "#     buffer.seek(0)\n",
    "#     x, sr = librosa.load(buffer, sr=None)\n",
    "#     label = json.load(open(\"train_sample_videos/metadata.json\"))[clean_file]['label']\n",
    "#     new_row = pd.DataFrame([[clean_file] + get_features(x, sr) + [label]], columns=column_ames)\n",
    "#     df = pd.concat([df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxacOcTrJVRc"
   },
   "outputs": [],
   "source": [
    "df.to_csv( \"/content/drive/MyDrive/SIH2024_DATASET/full_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PTTLrLhJVRc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
