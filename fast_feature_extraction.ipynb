{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwXA-5KIJapI",
        "outputId": "bc239792-9362-472a-c9ad-3439d396a0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgGqXEsT_fDQ",
        "outputId": "d99822a7-b708-4a29-b80c-b006ca948e80"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.36.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (10.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "H3eVgsMsJVRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e4d553-6ce2-4b44-8217-21d0f1875d8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cupy as cp\n",
        "from moviepy.editor import VideoFileClip\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import scipy.stats\n",
        "import soundfile as sf\n",
        "import io\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pickle as pk\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A9iF-QXJVRZ"
      },
      "source": [
        "Statistical Features  \n",
        "A first easy step is to compute the mean, standard deviation, minimum, maximum, median and quartiles of the frequencies of each signal. This can be done using Numpy and it always brings value to our feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ibnbShbMJVRa"
      },
      "outputs": [],
      "source": [
        "def describe_freq(freqs):\n",
        "    freqs = cp.array(freqs)  # Convert to CuPy array for GPU computation\n",
        "    mean = cp.mean(freqs)\n",
        "    std = cp.std(freqs)\n",
        "    maxv = cp.amax(freqs)\n",
        "    minv = cp.amin(freqs)\n",
        "    median = cp.median(freqs)\n",
        "    skew = scipy.stats.skew(cp.asnumpy(freqs))  # Skew not directly supported in CuPy\n",
        "    kurt = scipy.stats.kurtosis(cp.asnumpy(freqs))  # Kurtosis not directly supported in CuPy\n",
        "    q1 = cp.quantile(freqs, 0.25)\n",
        "    q3 = cp.quantile(freqs, 0.75)\n",
        "    mode = scipy.stats.mode(cp.asnumpy(freqs))[0][0]  # Mode not directly supported in CuPy\n",
        "    iqr = cp.subtract(q3, q1)\n",
        "\n",
        "    return [mean.get(), std.get(), maxv.get(), minv.get(), median.get(), skew, kurt, q1.get(), q3.get(), mode, iqr.get()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nNifSVyDJVRa"
      },
      "outputs": [],
      "source": [
        "def get_features(x, sr):\n",
        "    x = torch.tensor(x, device=device)  # Send to GPU\n",
        "    rmse = torch.mean(torch.tensor(librosa.feature.rms(y=x.cpu().numpy())[0], device=device))\n",
        "    zcr = torch.mean(torch.tensor(librosa.feature.zero_crossing_rate(x.cpu().numpy())[0], device=device))\n",
        "    tempo = torch.tensor(librosa.beat.tempo(y=x.cpu().numpy(), sr=sr)[0], device=device)\n",
        "    mfcc = torch.mean(torch.tensor(librosa.feature.mfcc(y=x.cpu().numpy(), sr=sr), device=device), axis=1)\n",
        "    spec_cen = torch.mean(torch.tensor(librosa.feature.spectral_centroid(y=x.cpu().numpy(), sr=sr), device=device))\n",
        "    spectral_bandwidth = torch.mean(torch.tensor(librosa.feature.spectral_bandwidth(y=x.cpu().numpy(), sr=sr), device=device))\n",
        "    spectral_contrast = torch.mean(torch.tensor(librosa.feature.spectral_contrast(y=x.cpu().numpy(), sr=sr), device=device))\n",
        "    spectral_flatness = torch.mean(torch.tensor(librosa.feature.spectral_flatness(y=x.cpu().numpy()), device=device))\n",
        "    spectral_rolloff = torch.mean(torch.tensor(librosa.feature.spectral_rolloff(y=x.cpu().numpy(), sr=sr), device=device))\n",
        "\n",
        "    features = [rmse, zcr, tempo, spec_cen, spectral_bandwidth, spectral_contrast, spectral_flatness, spectral_rolloff]\n",
        "    features = [f.item() for f in features] + [mfcc[i].item() for i in range(mfcc.size(0))]  # Convert to list\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file_path):\n",
        "    try:\n",
        "        # Load video file\n",
        "        video_clip = VideoFileClip(file_path)\n",
        "        audio = video_clip.audio\n",
        "        fps = audio.fps\n",
        "        audio_samples = cp.array(list(audio.iter_frames(fps=fps, dtype=\"float32\"))).flatten()\n",
        "        buffer = io.BytesIO()\n",
        "        sf.write(buffer, cp.asnumpy(audio_samples), fps, format=\"wav\")\n",
        "        buffer.seek(0)\n",
        "        x, sr = librosa.load(buffer, sr=None)\n",
        "        video_clip.close()\n",
        "        features = get_features(x, sr)\n",
        "        return features\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error encountered while parsing file: {file_path}, {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "6p0CSM2I_qGY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(real_dir, fake_dir, real_files, fake_files):\n",
        "    data = []\n",
        "    columns = [\"rmse\", \"zcr\", \"tempo\", \"spectral_centroid\", \"spectral_bandwidth\",\n",
        "               \"spectral_contrast\", \"spectral_flatness\", \"spectral_rolloff\"] + \\\n",
        "              [f\"mfcc{i}\" for i in range(1, 21)] + [\"label\"]\n",
        "\n",
        "    # Set up progress bar\n",
        "    total_files = len(real_files) + len(fake_files)\n",
        "    pbar = tqdm(total=total_files, desc=\"Processing files\", unit=\"file\")\n",
        "\n",
        "    # Process real audio files\n",
        "    for file_name in real_files:\n",
        "        file_path = os.path.join(real_dir, file_name)\n",
        "        features = extract_features(file_path)\n",
        "        if features is not None:\n",
        "            features.append(0)  # Label: 0 for REAL\n",
        "            data.append(features)\n",
        "        pbar.update(1)\n",
        "\n",
        "    # Process fake audio files\n",
        "    for file_name in fake_files:\n",
        "        file_path = os.path.join(fake_dir, file_name)\n",
        "        features = extract_features(file_path)\n",
        "        if features is not None:\n",
        "            features.append(1)  # Label: 1 for FAKE\n",
        "            data.append(features)\n",
        "        pbar.update(1)\n",
        "\n",
        "    pbar.close()\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "fiFT26TK_tA_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nL9J7Vp9JVRa"
      },
      "outputs": [],
      "source": [
        "real_audio_dir = r\"/content/drive/MyDrive/SIH2024_DATASET/FAKE\"\n",
        "fake_audio_dir = r\"/content/drive/MyDrive/SIH2024_DATASET/REAL\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\n",
        "    r\"/content/drive/MyDrive/SIH2024_DATASET/real_files.pkl\",\n",
        "    \"rb\",\n",
        ") as f:\n",
        "    real_files = pk.load(f)\n",
        "\n",
        "with open(\n",
        "    r\"/content/drive/MyDrive/SIH2024_DATASET/fake_files.pkl\",\n",
        "    \"rb\",\n",
        ") as f:\n",
        "    fake_files = pk.load(f)"
      ],
      "metadata": {
        "id": "gfwu2Ct2E5aQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUS-nOHOJVRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eee5356-bbdb-4941-a6a8-023a552db603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing files:   0%|          | 0/119146 [00:00<?, ?file/s]\u001b[AWARNING:py.warnings:<ipython-input-16-a7fd88b90afb>:5: FutureWarning: librosa.beat.tempo\n",
            "\tThis function was moved to 'librosa.feature.rhythm.tempo' in librosa version 0.10.0.\n",
            "\tThis alias will be removed in librosa version 1.0.\n",
            "  tempo = torch.tensor(librosa.beat.tempo(y=x.cpu().numpy(), sr=sr)[0], device=device)\n",
            "\n",
            "\n",
            "Processing files:   0%|          | 1/119146 [00:49<1636:30:03, 49.45s/file]\u001b[A\n",
            "Processing files:   0%|          | 2/119146 [00:54<781:18:28, 23.61s/file] \u001b[A\n",
            "Processing files:   0%|          | 3/119146 [01:02<536:02:40, 16.20s/file]\u001b[A\n",
            "Processing files:   0%|          | 4/119146 [01:08<401:05:04, 12.12s/file]\u001b[A\n",
            "Processing files:   0%|          | 5/119146 [01:14<329:52:16,  9.97s/file]\u001b[A\n",
            "Processing files:   0%|          | 6/119146 [01:20<292:03:36,  8.83s/file]\u001b[A\n",
            "Processing files:   0%|          | 7/119146 [01:26<252:24:15,  7.63s/file]\u001b[A\n",
            "Processing files:   0%|          | 8/119146 [01:33<249:16:37,  7.53s/file]\u001b[A\n",
            "Processing files:   0%|          | 9/119146 [01:39<233:18:09,  7.05s/file]\u001b[A\n",
            "Processing files:   0%|          | 10/119146 [01:45<219:08:22,  6.62s/file]\u001b[A\n",
            "Processing files:   0%|          | 11/119146 [01:50<207:42:15,  6.28s/file]\u001b[A\n",
            "Processing files:   0%|          | 12/119146 [01:56<201:16:48,  6.08s/file]\u001b[A\n",
            "Processing files:   0%|          | 13/119146 [02:03<208:24:18,  6.30s/file]\u001b[A\n",
            "Processing files:   0%|          | 14/119146 [02:07<193:09:17,  5.84s/file]\u001b[A\n",
            "Processing files:   0%|          | 15/119146 [02:14<198:54:47,  6.01s/file]\u001b[A\n",
            "Processing files:   0%|          | 16/119146 [02:20<196:33:28,  5.94s/file]\u001b[A\n",
            "Processing files:   0%|          | 17/119146 [02:25<195:16:37,  5.90s/file]\u001b[A\n",
            "Processing files:   0%|          | 18/119146 [02:31<196:34:55,  5.94s/file]\u001b[A\n",
            "Processing files:   0%|          | 19/119146 [02:37<190:39:26,  5.76s/file]\u001b[A\n",
            "Processing files:   0%|          | 20/119146 [02:44<201:17:12,  6.08s/file]\u001b[A\n",
            "Processing files:   0%|          | 21/119146 [02:49<191:47:34,  5.80s/file]\u001b[A\n",
            "Processing files:   0%|          | 22/119146 [02:56<204:24:15,  6.18s/file]\u001b[A\n",
            "Processing files:   0%|          | 23/119146 [03:01<198:39:45,  6.00s/file]\u001b[A\n",
            "Processing files:   0%|          | 24/119146 [03:07<190:32:43,  5.76s/file]\u001b[A\n",
            "Processing files:   0%|          | 25/119146 [03:13<196:45:13,  5.95s/file]\u001b[A\n",
            "Processing files:   0%|          | 26/119146 [03:18<188:10:05,  5.69s/file]\u001b[A\n",
            "Processing files:   0%|          | 27/119146 [03:28<231:42:08,  7.00s/file]\u001b[A\n",
            "Processing files:   0%|          | 28/119146 [03:34<217:59:00,  6.59s/file]\u001b[A\n",
            "Processing files:   0%|          | 29/119146 [03:42<239:25:45,  7.24s/file]\u001b[A\n",
            "Processing files:   0%|          | 30/119146 [03:51<251:43:50,  7.61s/file]\u001b[A\n",
            "Processing files:   0%|          | 31/119146 [03:58<251:02:08,  7.59s/file]\u001b[A\n",
            "Processing files:   0%|          | 32/119146 [04:04<228:25:39,  6.90s/file]\u001b[A\n",
            "Processing files:   0%|          | 33/119146 [04:10<218:30:08,  6.60s/file]\u001b[A\n",
            "Processing files:   0%|          | 34/119146 [04:16<212:45:49,  6.43s/file]\u001b[A\n",
            "Processing files:   0%|          | 35/119146 [04:21<202:28:58,  6.12s/file]\u001b[A"
          ]
        }
      ],
      "source": [
        "df = load_data(real_audio_dir, fake_audio_dir, fake_files, real_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tLFhSuVJVRc"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMej7SKRJVRc"
      },
      "outputs": [],
      "source": [
        "# for file in file_names:\n",
        "\n",
        "#     clean_file = file.split(\"/\")[-1]\n",
        "#     video_clip = VideoFileClip(file)\n",
        "#     audio = video_clip.audio\n",
        "#     fps = audio.fps\n",
        "#     audio_samples = np.array(list(audio.iter_frames(fps=fps, dtype=\"float32\"))).flatten()\n",
        "#     buffer = io.BytesIO()\n",
        "#     sf.write(buffer, audio_samples, fps, format='wav')\n",
        "#     buffer.seek(0)\n",
        "#     x, sr = librosa.load(buffer, sr=None)\n",
        "#     label = json.load(open(\"train_sample_videos/metadata.json\"))[clean_file]['label']\n",
        "#     new_row = pd.DataFrame([[clean_file] + get_features(x, sr) + [label]], columns=column_ames)\n",
        "#     df = pd.concat([df, new_row], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxacOcTrJVRc"
      },
      "outputs": [],
      "source": [
        "df.to_csv( \"/content/drive/MyDrive/SIH2024_DATASET/full_features.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PTTLrLhJVRc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}